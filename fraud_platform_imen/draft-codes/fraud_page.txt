import os
from PIL import Image
import streamlit as st
import easyocr
import cv2
import matplotlib.pyplot as plt
import json
import spacy
from spacy.tokens import DocBin
from spacy.util import filter_spans
from tqdm import tqdm


import nltk
nltk.download('punkt')
nltk.download('stopwords')

import pandas as pd
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

import random

from spacy import displacy
from fpdf import FPDF
import numpy as np
from sklearn import tree

from PIL import Image
import pytesseract
import ner_app  # Import the functions from the ner_app.py file
import base64
#-----------------------------------------SET BACKGROUND IMAGE--------------------------------------
def get_base64(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

def set_background(png_file):
    bin_str = get_base64(png_file)
    page_bg_img = '''
    <style>
    .stApp {
    background-image: url("data:image/png;base64,%s");
    background-size: cover;
    }
    </style>
    ''' % bin_str
    st.markdown(page_bg_img, unsafe_allow_html=True)

#-----------------------------------------FRAUD PAGE--------------------------------------
def app():
    st.write("Welcome to Fraud Detection")
    set_background('C:/fraud_platform_imen/image.png')
    if os.path.exists('./updated_ner_results1.xlsx'): 
         df = pd.read_excel('updated_ner_results1.xlsx'.xlsx_file, header=0)
    # or we can do : file = st.file_uploader("Upload Your Dataset")

    #Data preparation
    # Replace NaN values in the 'Dosage' column with a space
    df['DOSAGE'] = df['DOSAGE'].fillna(' ')
    # Replace NaN values in the 'Dosage' column with a space
    df['DRUGNAME'] = df['DRUGNAME'].fillna(' ')
    # Replace NaN values in the 'Dosage' column with a space
    df['SIZE'] = df['SIZE'].fillna(' ')
    # Replace NaN values in the 'Dosage' column with a space
    df['COMPOSITION'] = df['COMPOSITION'].fillna(' ')
 # Replace NaN values in the 'Dosage' column with a space
    df['TYPE'] = df['TYPE'].fillna(' ')

    # Calculate Jaccard similarity and determine fraud status
    max_jaccard_score = -1
    max_jaccard_index = -1
    
    doc = ner_app.perform_named_entity_recognition(text)
    detail = ner_app.details_dict(doc)
    example_ner_list = [detail.get("DRUGNAME"), detail.get("TYPE"), detail.get("COMPOSITION"),
                                detail.get("SIZE"), detail.get("DOSAGE")]
    example_ner_list = [item for sublist in example_ner_list if item is not None]

    flattened_list = [item for sublist in example_ner_list for item in sublist]
    example_tokens = word_tokenize(' '.join(map(str, flattened_list)))
            

    for index, row in df.iterrows():
                base_ner_list = [row['DRUGNAME'], row['TYPE'], row['COMPOSITION'], row['SIZE'], row['DOSAGE']]
                base_tokens = word_tokenize(' '.join(map(str, base_ner_list)))

                # Remove stopwords
                stop_words = set(stopwords.words("english"))
                filtered_base_tokens = [token for token in base_tokens if token.lower() not in stop_words]
                filtered_example_tokens = [token for token in example_tokens if token.lower() not in stop_words]
                # Calculate Jaccard similarity score
                jaccard_similarity = ner_app.ner_list_similarity_jaccard(filtered_base_tokens, filtered_example_tokens)

                if jaccard_similarity > max_jaccard_score:
                            max_jaccard_score = jaccard_similarity
                            max_jaccard_index = index

    if max_jaccard_index != -1:
                    entities = df.loc[max_jaccard_index]

    threshold = 0.4
    if max_jaccard_score > threshold:
                    fraud_status = "This Drug is not potentially fraudulent"
    else:
                    fraud_status = "This Drug is potentially fraudulent"

    # Display results
    st.write("Max Jaccard Similarity Score:", max_jaccard_score)
    st.write("Entities from the dataset with max similarity:", entities)
    st.write("Fraud Status:", fraud_status)